{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm',disable=[\"tagger\", \"parser\"])\n",
    "\n",
    "w2s = np.load('word2seq.npy',allow_pickle='TRUE').item()\n",
    "\n",
    "model = load_model('TC.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title('Toxic Comment Filter')\n",
    "st.write('Discussing things you care about can be difficult.' \n",
    "         'The threat of abuse and harassment online means that many people stop expressing themselves and',\n",
    "         'give up on seeking different opinions. Platforms struggle to effectively facilitate conversations,',\n",
    "         'leading many communities to limit or completely shut down user comments.')\n",
    "st.write('This application helps in detecting toxic comments. This was developed on the comments from Wikipediaâ€™s talk page edits.')\n",
    "user_input = st.text_input(\"Enter your comment here\",'good application though.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.zeros((1,30))\n",
    "i = 0\n",
    "unknown = 0\n",
    "\n",
    "doc = nlp(user_input)\n",
    "\n",
    "for token in doc:\n",
    "    if token.is_stop == False:\n",
    " \n",
    "        low_txt = token.text.lower()\n",
    "\n",
    "        if str(low_txt) in w2s:\n",
    "            \n",
    "            arr[0][i] = w2s[low_txt]\n",
    "            i = i + 1\n",
    "        else:\n",
    "            st.write('The word',token,'was not found in the dictionary')\n",
    "            unknown = 1\n",
    "            \n",
    "if unknown == 0:       \n",
    "    \n",
    "    toxicity = model.predict(arr)\n",
    "    tox = str(int(round(toxicity[0][0] * 10)))\n",
    "    if toxicity > 0.5:\n",
    "        st.write(\"This comment is predicted to be an hate comment. On a toxic scale of 1 to 10 this comment rates\",tox)\n",
    "    else:\n",
    "        st.write(\"This comment is predicted to be hate free.\")\n",
    "        \n",
    "if unknown == 1:\n",
    "    st.write(\"Try again.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
