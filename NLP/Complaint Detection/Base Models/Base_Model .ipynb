{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "nlp = English()\n",
    "import gensim.downloader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.263108e+16</td>\n",
       "      <td>@FC_HELP can I return online purchases to a Ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>apparel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.336408e+16</td>\n",
       "      <td>@FC_Help Hi - I'm writing a piece for MSN Him ...</td>\n",
       "      <td>0</td>\n",
       "      <td>apparel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              tweet  label  \\\n",
       "0  2.263108e+16  @FC_HELP can I return online purchases to a Ho...      0   \n",
       "1  2.336408e+16  @FC_Help Hi - I'm writing a piece for MSN Him ...      0   \n",
       "\n",
       "    domain  \n",
       "0  apparel  \n",
       "1  apparel  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('cd.csv')\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glv = gensim.downloader.load(\"glove-twitter-200\") #https://radimrehurek.com/gensim/downloader.html?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\envs\\python37\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df2 = df1.copy()\n",
    "p = 0\n",
    "n = 0\n",
    "l = 0\n",
    "m = 0\n",
    "\n",
    "for count, tweet in enumerate(df2.tweet):\n",
    "    dummy = []\n",
    "    m += len(nlp(tweet))\n",
    "    if len(nlp(tweet)) > l:\n",
    "        l = len(nlp(tweet)) \n",
    "    for word in nlp(tweet):\n",
    "        try:\n",
    "            dummy.append(glv.wv[str(word)])\n",
    "            p+=1\n",
    "        except:\n",
    "            rand = np.zeros(200)\n",
    "            dummy.append(rand)\n",
    "            n+=1\n",
    "            \n",
    "    df2.at[count, 'tweet'] = dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in Glove dictionary : 45418\n",
      "Words not in Glove dictionary : 15066\n",
      "Longest tweet length : 60\n",
      "Average tweet length : 17.53667729776747\n"
     ]
    }
   ],
   "source": [
    "print('Words in Glove dictionary :', p)\n",
    "print('Words not in Glove dictionary :', n)\n",
    "print('Longest tweet length :', l)\n",
    "print('Average tweet length :', m/len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 20\n",
    "df3 = df2.copy()\n",
    "\n",
    "for count, tweet in enumerate(df2.tweet):\n",
    "    tw_len = len(tweet)\n",
    "    #print(tw_len)\n",
    "    #print(tweet)\n",
    "    content = df2.tweet[count]\n",
    "    if tw_len < max_len:\n",
    "        for i in range(max_len - tw_len):\n",
    "            content.append(np.zeros((1, 200))[0])\n",
    "        df2.at[count, 'tweet'] = np.stack(content)\n",
    "    else:\n",
    "        df2.at[count, 'tweet'] = np.stack(df2.at[count, 'tweet'][:max_len]) \n",
    "        \n",
    "    df2.at[count, 'tweet'] = np.ndarray.flatten(df2.tweet[count]).reshape((1, max_len * 200)).astype(np.float32)  \n",
    "    df3.at[count, 'tweet'] = np.array(df2.tweet[count]).reshape((1, max_len, 200)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx1 = np.stack(df2.tweet).reshape((len(df2), 1, max_len * 200))\n",
    "trainy1 = np.stack(df2.label).reshape((len(df2), 1))\n",
    "\n",
    "train_data1 = tf.data.Dataset.from_tensor_slices((trainx1, trainy1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_1 = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(100, activation = \"relu\", name = \"layer1\"),\n",
    "        layers.Dense(1, activation = \"sigmoid\", name = \"layer2\"),\n",
    "    ])\n",
    "\n",
    "# Call model on a test input\n",
    "x = df2.tweet[1]\n",
    "y = base_model_1.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               multiple                  400100    \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               multiple                  101       \n",
      "=================================================================\n",
      "Total params: 400,201\n",
      "Trainable params: 400,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3449/3449 [==============================] - 11s 3ms/step - loss: 0.5199 - recall: 0.6526\n",
      "Epoch 2/5\n",
      "3449/3449 [==============================] - 12s 3ms/step - loss: 0.2620 - recall: 0.8369\n",
      "Epoch 3/5\n",
      "3449/3449 [==============================] - 11s 3ms/step - loss: 0.0904 - recall: 0.9481\n",
      "Epoch 4/5\n",
      "3449/3449 [==============================] - 12s 3ms/step - loss: 0.0625 - recall: 0.9643\n",
      "Epoch 5/5\n",
      "3449/3449 [==============================] - 12s 3ms/step - loss: 0.0483 - recall: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11be4b4f188>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_1.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "                     metrics = tf.keras.metrics.Recall(name = 'recall'))\n",
    "base_model_1.fit(train_data1, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.49748182296753 % the tweet is a complaint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\envs\\python37\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\ADMIN\\anaconda3\\envs\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "comp = '@adidas I ordered a sneakers last month and yet to recieve. Will I get it atleat by this month?'\n",
    "\n",
    "test = []\n",
    "\n",
    "for word in nlp(comp):\n",
    "    try:\n",
    "        test.append(glv.wv[str(word)])\n",
    "        p+=1\n",
    "    except:\n",
    "        rand = np.zeros(200)\n",
    "        test.append(rand)\n",
    "        n+=1\n",
    "        \n",
    "for i in range(max_len - len(test)):\n",
    "    test.append(np.zeros((1, 200))[0])\n",
    "if len(test) > max_len:\n",
    "    test = test[:max_len]\n",
    "\n",
    "test = np.stack(test)\n",
    "test = np.ndarray.flatten(test)\n",
    "\n",
    "print(float(base_model_1(test.reshape((1, max_len * 200)))[0][0]) * 100, '% the tweet is a complaint.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uncomment the following cell for training using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score fold number 1: loss of 1.1272565126419067; recall of 58.91088843345642%\n",
      "Score fold number 2: loss of 1.2913845777511597; recall of 58.23389291763306%\n",
      "Score fold number 3: loss of 1.147955060005188; recall of 61.369192600250244%\n"
     ]
    }
   ],
   "source": [
    "# kfold = KFold(n_splits = 3, shuffle = True)\n",
    "\n",
    "# fold_no = 1\n",
    "# for train, test in kfold.split(trainx, trainy):\n",
    "\n",
    "#     # Define the model architecture\n",
    "#     base_model_1 = keras.Sequential(\n",
    "#         [\n",
    "#             layers.Dense(100, activation = \"relu\", name = \"layer1\"),\n",
    "#             layers.Dense(1, activation = \"sigmoid\", name = \"layer2\"),\n",
    "#         ])\n",
    "\n",
    "#     # Compile the model\n",
    "#     base_model_1.compile(optimizer = tf.keras.optimizer.Adam(learning_rate = 0.01, name = 'Adam'), \n",
    "#                          loss = tf.keras.losses.BinaryCrossentropy(), metrics = tf.keras.metrics.Recall(name = 'recall'))\n",
    "\n",
    "#     # Fit data to model\n",
    "#     history = base_model_1.fit(trainx[train], trainy[train], epochs = 20, verbose = 0)\n",
    "\n",
    "#     # Generate generalization metrics\n",
    "#     scores = base_model_1.evaluate(trainx[test], trainy[test], verbose=0)\n",
    "#     print(f'Score fold number {fold_no}: {base_model_1.metrics_names[0]} of {scores[0]}; {base_model_1.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "#     fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx2 = np.stack(df3.tweet).reshape((len(df2), 1, max_len, 200))\n",
    "trainy2 = np.stack(df3.label).reshape((len(df2), 1))\n",
    "\n",
    "train_data2 = tf.data.Dataset.from_tensor_slices((trainx2, trainy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               multiple                  50200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  51        \n",
      "=================================================================\n",
      "Total params: 50,251\n",
      "Trainable params: 50,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "base_model_2 = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.LSTM(units = 50),\n",
    "        keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "x = df3.tweet[1]\n",
    "y = base_model_2.predict(x)\n",
    "\n",
    "print(base_model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3449/3449 [==============================] - 20s 6ms/step - loss: 0.1208 - recall: 0.9351\n",
      "Epoch 2/5\n",
      "3449/3449 [==============================] - 21s 6ms/step - loss: 0.0916 - recall: 0.9578\n",
      "Epoch 3/5\n",
      "3449/3449 [==============================] - 22s 6ms/step - loss: 0.0922 - recall: 0.9537\n",
      "Epoch 4/5\n",
      "3449/3449 [==============================] - 21s 6ms/step - loss: 0.0601 - recall: 0.9716\n",
      "Epoch 5/5\n",
      "3449/3449 [==============================] - 18s 5ms/step - loss: 0.0591 - recall: 0.9708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11be205d088>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_2.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "                     metrics = tf.keras.metrics.Recall(name = 'recall'))\n",
    "base_model_2.fit(train_data2, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.11834454536438 % the tweet is a complaint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\envs\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "comp = '@adidas I ordered a sneakers last month and yet to recieve. Will I get it atleat by this month?'\n",
    "\n",
    "test = []\n",
    "\n",
    "for word in nlp(comp):\n",
    "    try:\n",
    "        test.append(glv.wv[str(word)])\n",
    "        p+=1\n",
    "    except:\n",
    "        rand = np.zeros(200)\n",
    "        test.append(rand)\n",
    "        n+=1\n",
    "        \n",
    "for i in range(max_len - len(test)):\n",
    "    test.append(np.zeros((1, 200))[0])\n",
    "if len(test) > max_len:\n",
    "    test = test[:max_len]\n",
    "\n",
    "test = np.stack(test)\n",
    "test = test.reshape((1, max_len, 200))\n",
    "print(float(base_model_2(test)[0][0]) * 100, '% the tweet is a complaint.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
